{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep learning based diffusive size factors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook illustrates the use of the deep learning based diffusive conductance algorithm decribed [here](https://doi.org/10.1016/j.cageo.2022.105086). PoreSpy's `AI_size_factor` includes the steps for predicting the diffusive size factors of the conduit images. Note that the diffusive conductance of the conduits can be then calculated by multiplying the size factor by diffusivity of the phase. The function takes in the images of segmented porous medium and returns an array of diffusive size factors for all conduits in the image. Therefore, the framework can be applied to both one conduit image as well as a segmented image of porous medium:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://user-images.githubusercontent.com/43128873/116145783-bd458380-a6ab-11eb-8103-fb9a93f0599c.png\" alt=\"PS_dl\" width=\"500\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trained model and supplementary materials\n",
    "To use the `AI_size_factor`, the tained trained model or weight, and trained data distribution are required. These files based on training images of polydispersed spheres are available to download. Once the required files are downloaded, we can then pass the directory of the files to `AI_size_factor` to be used for predictions.\n",
    "\n",
    "[trained model](link): This file includes both weights and architecture of the deep learning layers. To use this file, there is no need to build a model.\n",
    "\n",
    "[trained model weights only](link): This file includes only weights of the deep learning layers. To use this file, a Resnet50 model will be built automatically in the `AI_size_factor`.\n",
    "\n",
    "[trained data distribution](link): This file will be used in denormalizing predicted values based on normalized transform applied on training data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import necessary packages and functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import porespy as ps\n",
    "import scipy as sp\n",
    "import numpy as np\n",
    "import h5py\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.metrics import r2_score\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "# path to the downloaded supplementary materials, by default current directory is used here:\n",
    "path = os.getcwd()+'/'\n",
    "model_dir = path+'saved_model.h5'\n",
    "g_train_dir = './AI_example_data/g_train_original.hdf5'\n",
    "f_in = h5py.File(g_train_dir, 'r')\n",
    "g_train = f_in['g_train'][()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create test image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can create a 3D image using PoreSpy's `poly_disperese_spheres` generator and segment the image using `snow_partitioning methods`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(17)\n",
    "shape = [150, 150, 150]\n",
    "dist = sp.stats.norm(loc=7, scale=5)\n",
    "im = ps.generators.polydisperse_spheres(shape=shape,\n",
    "                                        porosity=0.5,\n",
    "                                        dist=dist,\n",
    "                                        r_min=7)\n",
    "results = ps.filters.snow_partitioning(im=im.astype(bool))\n",
    "regions = results['regions']\n",
    "fig, ax = plt.subplots(1, 1, figsize=[4, 4])\n",
    "ax.imshow(regions[:,:,20], origin='lower', interpolation='none')\n",
    "ax.axis(False);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply AI_size_factor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `AI_size_factor` function has an optional arguemnt to choose the method to predict on the test images. If `tensor_wise=True`, the size factors for all conduits will be calculated once using a tensor of conduit images. By default `tensor_wise=False`, which indicates that the size factors for each conduit will be calculated separately in a for loop. To speedup the calculations, it is recommended to choose `tensor_wise=True`, as tensorflow deep learning model is designed to work with tensors. As the size of the image icreases, the runtime difference between these two options becomes larger."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "size_factors = ps.networks.AI_size_factor(regions, model_dir=model_dir, g_train=g_train, tensor_wise=True )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare with finite difference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assuming a diffusivity of 1, the diffusive conductance of the conduits will be equal to their size factors. Now let's compare the AI-based diffusive conductances with the conductance values calculated by finite difference method. The finite difference method results are found using the steps explained [here](https://doi.org/10.1016/j.cageo.2022.105086)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_in_pred = h5py.File('./AI_example_data/g_finite_difference.hdf5', 'r')\n",
    "g_pred = f_in_pred['g_finite_difference'][()]\n",
    "g_truth=size_factors\n",
    "plt.figure(figsize=[4,4])\n",
    "plt.xlim([0,65])\n",
    "plt.ylim([0,65])\n",
    "plt.plot(g_truth,g_pred,'*',[0,65],[0,65],'r')\n",
    "plt.xlabel('g reference')\n",
    "plt.ylabel('g prediction')\n",
    "r2=r2_score(g_truth, g_pred)\n",
    "print('The r2 prediction accuracy is', np.round(r2,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note on runtime: A larger part of `AI_size_factors` runtime is related to extracting the pairs of conduits, which is the common step required for both AI and finite difference method. Once the data is prepared, AI Prediction on the tensor takes a smaller amount of time in contrast to finite difference method, as it was shown [here]((https://doi.org/10.1016/j.cageo.2022.105086)). "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
